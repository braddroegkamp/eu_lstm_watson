{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lstm_pred = lstm.predict(X_test, batch_size=batch_size)\n",
    "lstm_mae = mean_absolute_error(sc_y.inverse_transform(y_test), sc_y.inverse_transform(lstm_pred))\n",
    "\n",
    "lr_pred = lr_model.transform(mlr_test)\n",
    "mae_eval = RegressionEvaluator().setMetricName(\"mae\") .setPredictionCol(\"prediction\").setLabelCol(\"label\")\n",
    "lr_mae = mae_eval.evaluate(lr_pred)\n",
    "\n",
    "print('LSTM Mean Absolute Error (Test set): ' + str(round(lstm_mae, 5)))\n",
    "print(' MLR Mean Absolute Error (Test set): ' + str(round(lr_mae, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, I've reached my usage limit on IBM Watson Studio, \n",
    "# so I'm going to recreate the LSTM model above outside of Watson Studio.\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this is ugly due to methods when shifting between Spark when in Watson studio, and not\n",
    "# had to reshift price_5min_return and resize df in order to lineup with predictions\n",
    "df_test_2 = df_test\n",
    "df_test_2['5min_return'] = df_test_2['price_5min_return'].shift(-5)\n",
    "df_test_2 = df_test_2[df_test_2.is_in_dataset][0:len(sc_y_test.inverse_transform(lstm_pred))]\n",
    "df_test_2['prediction'] = sc_y_test.inverse_transform(lstm_pred)\n",
    "df_test_2['price_5min_pred'] = df_test_2['Close'] + df_test_2['prediction']\n",
    "\n",
    "# pick random day that isn't start of year where very uncommonly low volume exists\n",
    "df_2017_02_06 = df_test_2[(df_test_2.index >= '2017-02-06') & (df_test_2.index <= '2017-02-07')]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "df_2017_02_06['5min_return'].plot(ax=ax[0])\n",
    "df_2017_02_06['prediction'].plot(ax=ax[0])\n",
    "ax[0].set_ylabel(\"Returns\")\n",
    "ax[0].set_title(\"EUR/USD Returns vs Prediction on Feb 6, 2017\", fontsize=16)\n",
    "ax[0].legend()\n",
    "\n",
    "df_2017_02_06['Close'].plot(ax=ax[1], linestyle='--')\n",
    "df_2017_02_06['price_5min_pred'].shift(5).plot(ax=ax[1], linestyle='-.')\n",
    "ax[1].set_ylabel(\"Price\")\n",
    "ax[1].set_title(\"EUR/USD Price vs Prediction on Feb 6, 2017\", fontsize=16)\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy, as calculated based on  (Prediction Direction Correct / Total), here for LSTM and LR\n",
    "df_test_2['direction_correct'] = df_test_2['5min_return'] * df_test_2['prediction'] > 0\n",
    "print('Model Direction Accuracy: ' + str(round(df_test_2['direction_correct'].mean()*100, 2)) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
